{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticsRegression\n",
    "from sklearn import neighbors\n",
    "cp, cp downloads\n",
    "cancer=pd.read_csv('KNN.csv')\n",
    "del cancer['id']\n",
    "cancer\n",
    "import seaborn as sns\n",
    "sns.countplot(cancer['diagnosis'])\n",
    "#Sampling\n",
    "X=cancer.iloc[:,1:]\n",
    "Y=cancer.iloc[:,:1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "#training\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "#testing\n",
    "Y_pred=model.predict(X_test)\n",
    "Y_pred\n",
    "#Evluation\n",
    "#Confusion Matrix\n",
    "print(metrics.confusion_matrix(Y_test,Y_pred))\n",
    "Y_test['diagnosis'].value_counts()#just\n",
    "#classification Report\n",
    "print(metrics.classification_report(Y_test,Y_pred))\n",
    "#ACCURACY SCORE\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Downloads\n"
     ]
    }
   ],
   "source": [
    "cd Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer=pd.read_csv('KNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cancer['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>B</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.22</td>\n",
       "      <td>84.28</td>\n",
       "      <td>537.3</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>...</td>\n",
       "      <td>14.90</td>\n",
       "      <td>23.89</td>\n",
       "      <td>95.10</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>B</td>\n",
       "      <td>10.26</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.20</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.02037</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>19.48</td>\n",
       "      <td>70.89</td>\n",
       "      <td>357.1</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.07162</td>\n",
       "      <td>0.04074</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.08488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>M</td>\n",
       "      <td>15.28</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>...</td>\n",
       "      <td>17.80</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>B</td>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.13730</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>M</td>\n",
       "      <td>21.37</td>\n",
       "      <td>15.10</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>...</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.84</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.08666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           B        12.32         12.39           78.85      464.1   \n",
       "1           B        10.60         18.95           69.28      346.4   \n",
       "2           B        11.04         16.83           70.92      373.2   \n",
       "3           B        11.28         13.39           73.00      384.8   \n",
       "4           B        15.19         13.21           97.65      711.8   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         B        13.17         18.22           84.28      537.3   \n",
       "565         B        10.26         14.71           66.20      321.6   \n",
       "566         M        15.28         22.41           98.92      710.6   \n",
       "567         B        14.53         13.98           93.86      644.2   \n",
       "568         M        21.37         15.10          141.30     1386.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  points_mean  \\\n",
       "0            0.10280           0.06981         0.03987      0.03700   \n",
       "1            0.09688           0.11470         0.06387      0.02642   \n",
       "2            0.10770           0.07804         0.03046      0.02480   \n",
       "3            0.11640           0.11360         0.04635      0.04796   \n",
       "4            0.07963           0.06934         0.03393      0.02657   \n",
       "..               ...               ...             ...          ...   \n",
       "564          0.07466           0.05994         0.04859      0.02870   \n",
       "565          0.09882           0.09159         0.03581      0.02037   \n",
       "566          0.09057           0.10520         0.05375      0.03263   \n",
       "567          0.10990           0.09242         0.06895      0.06495   \n",
       "568          0.10010           0.15150         0.19320      0.12550   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.1959  ...         13.50          15.64            86.97   \n",
       "1           0.1922  ...         11.88          22.94            78.28   \n",
       "2           0.1714  ...         12.41          26.44            79.93   \n",
       "3           0.1771  ...         11.92          15.77            76.53   \n",
       "4           0.1721  ...         16.20          15.73           104.50   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1454  ...         14.90          23.89            95.10   \n",
       "565         0.1633  ...         10.88          19.48            70.89   \n",
       "566         0.1727  ...         17.80          28.03           113.80   \n",
       "567         0.1650  ...         15.80          16.93           103.10   \n",
       "568         0.1973  ...         22.69          21.84           152.10   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         549.1            0.1385             0.1266          0.12420   \n",
       "1         424.8            0.1213             0.2515          0.19160   \n",
       "2         471.4            0.1369             0.1482          0.10670   \n",
       "3         434.0            0.1367             0.1822          0.08669   \n",
       "4         819.1            0.1126             0.1737          0.13620   \n",
       "..          ...               ...                ...              ...   \n",
       "564       687.6            0.1282             0.1965          0.18760   \n",
       "565       357.1            0.1360             0.1636          0.07162   \n",
       "566       973.1            0.1301             0.3299          0.36300   \n",
       "567       749.9            0.1347             0.1478          0.13730   \n",
       "568      1535.0            0.1192             0.2840          0.40240   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0         0.09391          0.2827          0.06771  \n",
       "1         0.07926          0.2940          0.07587  \n",
       "2         0.07431          0.2998          0.07881  \n",
       "3         0.08611          0.2102          0.06784  \n",
       "4         0.08178          0.2487          0.06766  \n",
       "..            ...             ...              ...  \n",
       "564       0.10450          0.2235          0.06925  \n",
       "565       0.04074          0.2434          0.08488  \n",
       "566       0.12260          0.3175          0.09772  \n",
       "567       0.10690          0.2606          0.07810  \n",
       "568       0.19660          0.2730          0.08666  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here there are two types of cancer B or M and others are all parameters. so this is descrete result. we will use use logstics regretions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2213a1cdec8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(cancer['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling\n",
    "X=cancer.iloc[:,1:] #spliting input and output data set\n",
    "Y=cancer.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis\n",
       "0         B\n",
       "1         B\n",
       "2         B\n",
       "3         B\n",
       "4         B"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "(455, 1)\n",
      "(114, 30)\n",
      "(114, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traning\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'M', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'M',\n",
       "       'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63  3]\n",
      " [ 3 45]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "#Confusion Matrix :\n",
    "print(metrics.confusion_matrix(Y_test,Y_pred))\n",
    "#63 out of 66B is predicted correctly , 63 b is correctly predicted as b and they were actually a \"b\"\n",
    "#45 out of 48M is predicted correctly , 45 m is correctly predicted as m and they were actually a \"m\"\n",
    "#3 out of 66B is predicted wrongly as M , 3 b out of 66b is wrongly predicted as M\n",
    "#3 out of 48M is predicted wrongly as B , 3 m out of 48m is wrongly predicted as B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    66\n",
       "M    48\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test['diagnosis'].value_counts() #Actual y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.95      0.95        66\n",
      "           M       0.94      0.94      0.94        48\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification Report:\n",
    "print(metrics.classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
